{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "from nn_spikes import NeuralNetwork, batchTrain, test\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasources/spikes/training_data.csv')\n",
    "spikeLocations = pd.read_csv('./datasources/spikes/training_spike_locations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandPassFilter(signal, lowCut=300.00, highCut=3000.00, sampleRate=25000, order=1):\n",
    "    \n",
    "    # TODO: Calculate something\n",
    "    nyq = 0.5 * sampleRate\n",
    "    low = lowCut / nyq\n",
    "    high = highCut / nyq\n",
    "    \n",
    "    # Generate filter coefficients for butterworth filter\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "\n",
    "    signalFiltered = lfilter(b, a, signal)\n",
    "    return signalFiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPeaks(data, threshold=1.0):\n",
    "    df = data.loc[data['signalFiltered'] > threshold]\n",
    "    \n",
    "    valleys = df[(df['signalFiltered'].shift(1) > df['signalFiltered']) &\n",
    "                 (df['signalFiltered'].shift(-1) > df['signalFiltered'])]\n",
    "    \n",
    "    peaks = df[(df['signalFiltered'].shift(1) < df['signalFiltered']) &\n",
    "               (df['signalFiltered'].shift(-1) < df['signalFiltered'])]\n",
    "    \n",
    "    return peaks.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get putative spike waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpikeWaveform(spikes, data, window=100):\n",
    "    \n",
    "    if 'waveform' not in spikes.columns:\n",
    "        spikes.insert(len(spikes.columns), 'waveform', None)\n",
    "    \n",
    "    for index in spikes.index:\n",
    "        \n",
    "        waveform = data.loc[index-int(window/4):index+int(3/4*window), 'signal'].tolist()\n",
    "        waveformSmooth = bandPassFilter(waveform)\n",
    "        spikes.at[index, 'waveform'] = waveformSmooth\n",
    "        \n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get signal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignal(signal, peaks):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=signal,\n",
    "        mode='lines',\n",
    "        name='Signal'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=peaks,\n",
    "        y=[signal[j] for j in peaks],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color='red',\n",
    "            symbol='cross'\n",
    "        ),\n",
    "        name='Detected Peaks'\n",
    "    ))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearningCurves(results):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for key in results.keys():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=results[key]['trainingCurve'],\n",
    "            line=dict(width=1, dash='dash'),\n",
    "            name=str(key)+' training'\n",
    "        ))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=results[key]['validationCurve'],\n",
    "            mode='lines',\n",
    "            name=str(key)+' validation'\n",
    "        ))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResultsRepo(hiddenNodes=[200,500,700,900]):\n",
    "    results = {}\n",
    "    for depth in hiddenNodes:\n",
    "        results[str(depth)] = {'trainingCurve':[], \n",
    "                               'validationCurve':[],\n",
    "                               'trainingData':None, \n",
    "                               'validationData':None,\n",
    "                               'nn':None}\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConfusion(matrix, x=[0,1,2,3], y=[0,1,2,3]):\n",
    "    # change each element of z to type string for annotations\n",
    "    matrixText = [[str(y) for y in x] for x in matrix]\n",
    "\n",
    "    # set up figure \n",
    "    fig = ff.create_annotated_heatmap(matrix, x=x, y=y, annotation_text=matrixText, colorscale='Viridis')\n",
    "\n",
    "    # add title\n",
    "    fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "                      #xaxis = dict(title='x'),\n",
    "                      #yaxis = dict(title='x')\n",
    "                     )\n",
    "\n",
    "    # add custom xaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                            x=0.5,\n",
    "                            y=-0.15,\n",
    "                            showarrow=False,\n",
    "                            text=\"Predicted value\",\n",
    "                            xref=\"paper\",\n",
    "                            yref=\"paper\"))\n",
    "\n",
    "    # add custom yaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                            x=-0.35,\n",
    "                            y=0.5,\n",
    "                            showarrow=False,\n",
    "                            text=\"Real value\",\n",
    "                            textangle=-90,\n",
    "                            xref=\"paper\",\n",
    "                            yref=\"paper\"))\n",
    "\n",
    "    # adjust margins to make room for yaxis title\n",
    "    fig.update_layout(margin=dict(t=50, l=200))\n",
    "\n",
    "    # add colorbar\n",
    "    fig['data'][0]['showscale'] = True\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use labelled spikes to train the network, by first retrieving putative spike waveforms and passing it as input to NN. First we will split training data into training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitSpike = int(len(spikeLocations)*3/4)\n",
    "splitIndex = spikeLocations.iloc[splitSpike]['index']\n",
    "print(\"Split index: {}\\nSplit spike: {}\".format(splitIndex, splitSpike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = data.iloc[:splitIndex]\n",
    "data_validation = data.iloc[splitIndex:]\n",
    "print(\"training size: {}\\nvalidation size: {}\".format(data_training.shape[0], data_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['isPeak'] = False\n",
    "data.loc[spikeLocations['index'], 'isPeak'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = data.loc[data['isPeak']==True, :]\n",
    "spikes.insert(len(spikes.columns), 'class', spikeLocations['class'].values)\n",
    "spikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training and validation spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_training = spikes[:splitSpike]\n",
    "spikes_validation = spikes[splitSpike:]\n",
    "\n",
    "print(\"training size: {}\\nvalidation size: {}\".format(spikes_training.shape[0], spikes_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get spike waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=100\n",
    "spikes_training = getSpikeWaveform(spikes_training, data, window=z)\n",
    "spikes_validation = getSpikeWaveform(spikes_validation, data, window=z)\n",
    "spikes_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xRange = np.linspace(0,z, z+1)\n",
    "sample = spikes_training.iloc[20:40, 4].tolist()\n",
    "\n",
    "px.line(x=xRange, y=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = createResultsRepo(hiddenNodes=[200, 500, 700])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hid in results.keys():\n",
    "    \n",
    "    nn = NeuralNetwork(input_nodes=101, \n",
    "                       hidden_nodes=int(hid), \n",
    "                       output_nodes=4, \n",
    "                       lr=0.1,\n",
    "                       error_function='difference-squared')\n",
    "\n",
    "    nn, trainingCurve, validationCurve, df1, df2 = batchTrain(data_training=spikes_training,\n",
    "                                                                                    data_validation=spikes_validation,\n",
    "                                                                                    nn=nn,\n",
    "                                                                                    epochs=20,\n",
    "                                                                                    plotCurves=False)\n",
    "    results[hid]['nn'] = nn\n",
    "    results[hid]['trainingCurve'] = trainingCurve\n",
    "    results[hid]['validationCurve'] = validationCurve\n",
    "    results[hid]['trainingData'] = df1\n",
    "    results[hid]['validationData'] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plotLearningCurves(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.getConfusion(results['500']['validationData']['class'], results['500']['validationData']['classPrediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
