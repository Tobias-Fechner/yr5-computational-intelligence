{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nn_spikes import NeuralNetwork, batchTrain, test\n",
    "import spike_tools, utilities\n",
    "from nn_spikes import getInputsAndTargets\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasources/spikes/training_data.csv')\n",
    "spikeLocations = pd.read_csv('./datasources/spikes/training_spike_locations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, predictedSpikeIndexes = spike_tools.dataPreProcess(data, spikeLocations, waveformWindow=154, waveformSignalType='signalHPSavgol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training, data_validation, spikeIndexes_training, spikeIndexes_validation = spike_tools.splitData(data, predictedSpikeIndexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(input_nodes=len(data_training.loc[spikeIndexes_training[0], 'waveform']), \n",
    "                       hidden_nodes=735, \n",
    "                       output_nodes=4, \n",
    "                       lr=0.2,\n",
    "                       error_function='difference-squared')\n",
    "\n",
    "nn, trainingCurve, validationCurve = batchTrain(data_training=data_training,\n",
    "                                                              data_validation=data_validation,\n",
    "                                                              spikeIndexes_training=spikeIndexes_training, \n",
    "                                                              spikeIndexes_validation=spikeIndexes_validation, \n",
    "                                                              nn=nn,\n",
    "                                                              epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=trainingCurve,\n",
    "    line=dict(width=1, dash='dash'),\n",
    "    name='training'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=validationCurve,\n",
    "    mode='lines',\n",
    "    name='validation'\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3]:\n",
    "    spike_tools.getAverageWaveforms(data_training, spikeIndexes_training, classToPlot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSubmission = pd.read_csv('./datasources/spikes/submission_data.csv')\n",
    "dataSubmission.columns = ['time (s)', 'signal']\n",
    "dataSubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSubmission, predictedSpikeIndexes = spike_tools.dataPreProcess(dataSubmission, spikeLocations, detectPeaksOn='signalHPSavgol', threshold=0.9, waveformWindow=154, submission=True, waveformSignalType='signalHPSavgol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSubmission.loc[predictedSpikeIndexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataSubmission.iloc[25000:50000, :]\n",
    "spike_tools.plotSpikes(signals=[sample['signal'], \n",
    "                                sample['signalSavgol'], \n",
    "                                sample['signalSavgolBP'], \n",
    "                                sample['signalHP'], \n",
    "                                sample['signalHPSavgol']], \n",
    "                       spikes=[sample['predictedSpike']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an empty string to accumulate the count of correct predictions\n",
    "scorecard = []\n",
    "predictions = []\n",
    "\n",
    "# Iterate over each spike and query the trained neural network\n",
    "for index in predictedSpikeIndexes[1:]:\n",
    "\n",
    "    # Retrieve only the inputs (spike waveforms) to the network\n",
    "    inputs, _ = getInputsAndTargets(dataSubmission.loc[index, 'waveform'], nn.output_nodes, 0)\n",
    "\n",
    "    # Query the network to identify the predicted output for teh given spike waveform\n",
    "    prediction = nn.query(inputs)\n",
    "        \n",
    "    predictions.append(prediction)\n",
    "\n",
    "dataSubmission.loc[predictedSpikeIndexes, 'predictedClass'] = pd.Series(predictions, index=predictedSpikeIndexes[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectedSpikes = dataSubmission.loc[predictedSpikeIndexes]\n",
    "detectedSpikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0,1,2,3]:\n",
    "    print(\"{}: {}\".format(c, len(detectedSpikes[detectedSpikes['predictedClass'] == c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSubmission.loc[predictedSpikeIndexes[1:]].to_csv('./datasources/spikes/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctClasses = dataSubmission.loc[predictedSpikeIndexes[1:], 'predictedClass'] + 1\n",
    "correctClasses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "# Store the submission data according to the selected classifier\n",
    "Name = \"13243.mat\"\n",
    "spio.savemat(Name, {\"Index\":predictedSpikeIndexes[1:],\"Class\":correctClasses.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a dataframe containing only spike entries and select the waveform extracts for a given class\n",
    "detectedSpikes = dataSubmission.loc[predictedSpikeIndexes]\n",
    "classWaveforms = detectedSpikes[detectedSpikes['predictedClass'] == 3]['waveform']\n",
    "\n",
    "# Create vertical stack of all waveform values for that class\n",
    "stack = np.vstack(classWaveforms.values)\n",
    "\n",
    "# Create new list ready to store average values\n",
    "avgs = []\n",
    "\n",
    "# Loop over each column in stacked waveform values. This is equivalent to going point by point through the waveforms and taking\n",
    "# the averages of values at that point for all waveforms in that class\n",
    "for col in range(stack.shape[1]):\n",
    "    colAvg = np.average(stack[:, col])\n",
    "    # Store average of that point in a list. List will be of same length that the window is when extracting the waveforms\n",
    "    avgs.append(colAvg)\n",
    "\n",
    "# Store list of averages by casting to a series and appending at start of original store of waveforms\n",
    "# (this is to make indexing it straightforward as classes will contain different number of waveforms)\n",
    "classWaveforms = pd.Series([avgs]).append(classWaveforms)\n",
    "\n",
    "# Create new Plotly graph objects figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot all waveforms on the same figure, with 10% opacity. Then plot the average waveform in full opacity on top.\n",
    "for trace in classWaveforms[1:]:\n",
    "    fig.add_trace(go.Scatter(x=np.linspace(0, 100, 101),\n",
    "                             y=trace,\n",
    "                             mode='lines',\n",
    "                             line=dict(color='black'),\n",
    "                             opacity=0.1,\n",
    "                             ))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.linspace(0, 100, 101),\n",
    "                         y=classWaveforms[0],\n",
    "                         mode='lines', ))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
