{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising Character Classification Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3.nn_general import NeuralNetwork\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, nn):\n",
    "    # Train the neural network on each trainingsample\n",
    "    for record in data:\n",
    "\n",
    "        # Split the record by the commas\n",
    "        pixelValues = record.split(',')\n",
    "        label = pixelValues.pop(0)\n",
    "\n",
    "        # Scale and shift the inputs from 0..255 to 0.01..1\n",
    "        inputs = (np.asfarray(pixelValues) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # Create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(nn.output_nodes) + 0.01\n",
    "\n",
    "        # pixelValues[0] is the target label for this record\n",
    "        targets[int(label)] = 0.99\n",
    "\n",
    "        # Train the network\n",
    "        nn.train(inputs.tolist(), targets.tolist())\n",
    "        \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, nn):\n",
    "    \n",
    "    scorecard = []\n",
    "    successRate = 0\n",
    "    \n",
    "    for record in data:\n",
    "        # Split the record by commas\n",
    "        pixelValues = record.split(',')\n",
    "\n",
    "        # Correct label is the first value\n",
    "        correct_label = int(pixelValues.pop(0))\n",
    "\n",
    "        # Scale and shift the inputs\n",
    "        inputs = (np.asfarray(pixelValues)/255.0*0.99) + 0.01\n",
    "\n",
    "        # Query the network\n",
    "        outputs = nn.queryNN(inputs.tolist())\n",
    "\n",
    "        # Identify predicted label\n",
    "        prediction = np.argmax(outputs)\n",
    "\n",
    "        # Add to scorecard\n",
    "        if prediction == correct_label:\n",
    "            scorecard.append(1)\n",
    "        else:\n",
    "            scorecard.append(0)\n",
    "            \n",
    "    scorecard = np.asarray(scorecard)\n",
    "    successRate = (scorecard.sum()/scorecard.size)*100\n",
    "    return nn, successRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load len(500) Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_train_500.csv\", 'r')\n",
    "data_training = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_test_100.csv\", 'r')\n",
    "data_testing = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify nn parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hidden_nodes = [50, 75, 100, 200, 300, 500, 700, 900, 1100]\n",
    "lrs = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dict to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate Hidden Nodes and LR Over Train/ Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each number of hidden nodes\n",
    "for hidden_nodes in tqdm(x_hidden_nodes):\n",
    "    data = {}\n",
    "    \n",
    "    # Loop through each learning rate\n",
    "    for lr in lrs:\n",
    "        # Create new nn\n",
    "        nn = NeuralNetwork(input_nodes=784, \n",
    "                           hidden_nodes=hidden_nodes, \n",
    "                           output_nodes=10, \n",
    "                           lr=lr)\n",
    "        \n",
    "        # Train that nn 10 times (epochs)\n",
    "        for i in range(10):\n",
    "            nn = train(data_training, nn)\n",
    "            \n",
    "        # Test that nn, return also successRate\n",
    "        nn, successRate = test(data_testing, nn)\n",
    "        \n",
    "        # Store success rate *for that lr* in a dict\n",
    "        data[lr] = successRate\n",
    "        \n",
    "    # Store in dict containing success scores for each lr *for that number of hidden nodes* \n",
    "    results[str(hidden_nodes)] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[7, 7], dpi=100)\n",
    "ax1 = fig.add_subplot()\n",
    "\n",
    "ax1.set_xlabel('learning rate')\n",
    "ax1.set_ylabel('success rate, %')\n",
    "ax1.set_title('Network Performance with Learning Rate \\nand Number of Nodes in Hidden Layer')\n",
    "\n",
    "for i in results.keys():\n",
    "    x = results[i].keys()\n",
    "    y = results[i].values()\n",
    "    ax1.scatter(x, y, label=i, s=int(i))\n",
    "\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Hidden Nodes')\n",
    "ax1.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results.keys():\n",
    "    bestResult = max(results[i], key=lambda y: abs(results[i][y]))\n",
    "    print(i, bestResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Best Performers for Further Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create df because dataframes are nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_performance = pd.DataFrame(results)\n",
    "data_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select best 3 number of hidden nodes for each LR and sort by performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.DataFrame()\n",
    "\n",
    "for col in data_performance.columns:\n",
    "    # Get and sort column values as series\n",
    "    values = data_performance[col].sort_values(ascending=False)\n",
    "    # Select top three performers\n",
    "    tops = vals.iloc[:3]\n",
    "    \n",
    "    # Form into suitable df and append\n",
    "    df = pd.DataFrame(tops)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df.columns = ['learningRates','performance']\n",
    "    df['hiddenNodes'] = col\n",
    "    selected = selected.append(df, ignore_index=True)\n",
    "    \n",
    "selected.sort_values(by='performance', ascending=False, inplace=True, ignore_index=True)\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with More Data and Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training data with 1k lines instead of 500. (use same test dataset of 100 lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_train_1000.csv\", 'r')\n",
    "data_training = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each selected LR/ Hidden nodes combo and train a NN with 50 epochs instead of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_excel('.\\datasources\\selected.xlsx', index_col=0)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(selected.iterrows()):\n",
    "    # Create new nn\n",
    "    nn = NeuralNetwork(input_nodes=784, \n",
    "                       hidden_nodes=int(row['hiddenNodes']), \n",
    "                       output_nodes=10, \n",
    "                       lr=float(row['learningRates']))\n",
    "\n",
    "    # Train that nn 50 times (epochs)\n",
    "    for i in range(50):\n",
    "        nn = train(data_training, nn)\n",
    "\n",
    "    # Test that nn, return also successRate\n",
    "    nn, successRate = test(data_testing, nn)\n",
    "\n",
    "    # Store success rate *for that lr* in a dict\n",
    "    selected.at[index, 'performanceUpdated'] = successRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.sort_values(by='performanceUpdated', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.nlargest(8, 'performanceUpdated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nn:\n",
    "    \n",
    "else:\n",
    "    print(\"No network to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
