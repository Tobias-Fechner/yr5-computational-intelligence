{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nn_spikes import NeuralNetwork, batchTrain, test\n",
    "import spike_tools, utilities\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasources/spikes/training_data.csv')\n",
    "spikeLocations = pd.read_csv('./datasources/spikes/training_spike_locations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training, data_validation, spikeIndexes_training, spikeIndexes_validation = spike_tools.dataPreProcess(data, \n",
    "                                                                                                            spikeLocations=spikeLocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utilities.createResultsRepo([500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hid in results.keys():\n",
    "    \n",
    "    nn = NeuralNetwork(input_nodes=101, \n",
    "                       hidden_nodes=int(hid), \n",
    "                       output_nodes=4, \n",
    "                       lr=0.1,\n",
    "                       error_function='difference-squared')\n",
    "\n",
    "    nn, trainingCurve, validationCurve = batchTrain(data_training=data_training,\n",
    "                                                              data_validation=data_validation,\n",
    "                                                              spikeIndexes_training=spikeIndexes_training, \n",
    "                                                              spikeIndexes_validation=spikeIndexes_validation, \n",
    "                                                              nn=nn,\n",
    "                                                              epochs=30,\n",
    "                                                              plotCurves=False)\n",
    "    results[hid]['nn'] = nn\n",
    "    results[hid]['trainingCurve'] = trainingCurve\n",
    "    results[hid]['validationCurve'] = validationCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_tools.getAverageWaveforms(data_training, spikeIndexes_training, classToPlot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_submission = pd.read_csv('./datasources/spikes/submission_data.csv')\n",
    "data_submission.columns = ['time (s)', 'signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_submission, predictedSpikeIndexes_submission = spike_tools.dataPreProcess(data_submission, \n",
    "                                                                               threshold=1.0, \n",
    "                                                                               submission=True, \n",
    "                                                                               waveformSignalType='signalSavgol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_submission.iloc[2500:50000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_tools.plotSpikes([sample['signalFiltered'], sample['signal']], [sample['predictedSpike']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = data_submission[data_submission['predictedSpike']==True]['waveform']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = spike_tools.classifySpikesMLP(waveforms.iloc[1:], nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "signals = [data_submission['signal'][2000:8000], data_submission['signalFiltered'][2000:8000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for signal in signals:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=signal.index,\n",
    "        y=signal,\n",
    "        mode='lines',\n",
    "        name=signal.name,\n",
    "        opacity=0.5,\n",
    "    ))\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training['signalFilteredBP2'] = spike_tools.bandPassFilter(data_training['signal'], order=2)\n",
    "data_training['signalFilteredBP3'] = spike_tools.bandPassFilter(data_training['signal'], order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = 'savgol+BP'\n",
    "data_submission[oo] = savgol_filter(data_submission['signal'], 17, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_submission.iloc[100000:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_tools.plotSpikes([sample['signal'], \n",
    "                        sample['signalSavgol'], \n",
    "                        sample['signalSavgolBP']], [sample['predictedSpike']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
