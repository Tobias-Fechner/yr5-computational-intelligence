{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSpikeDetectionPerformance(knownSpikes, predictedSpikes, windowLeading=-1, windowTrailing=35):\n",
    "    # for each known spike, check if any index within the range index-windowLeading:index+windowTrailing is \n",
    "    # within the predicted spike index\n",
    "    \n",
    "    results = pd.DataFrame(index=predictedSpikes, columns=['predictionResult'])\n",
    "    falseNegatives = 0\n",
    "    falsePositives\n",
    "    \n",
    "    for known in knownSpikes:\n",
    "        allowable = np.arange(known-windowLeading, known+windowTrailing)\n",
    "        \n",
    "        below = predictedSpikes < max(allowable)\n",
    "        above = predictedSpikes > min(allowable)\n",
    "        \n",
    "        matches = predictedSpikes[above == below]\n",
    "        \n",
    "        if len(matches) == 1:\n",
    "            results.iloc[matches[0]] = 'TP'\n",
    "            continue\n",
    "        elif len(matches) == 0:\n",
    "            falseNegatives += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySpikes(waveforms, nn):\n",
    "\n",
    "    # Ensure data is of type pandas dataframe\n",
    "    assert isinstance(waveforms, pd.Series)\n",
    "\n",
    "    # Create an empty string to accumulate the count of correct predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over each row in the data\n",
    "    for waveform in waveforms:\n",
    "\n",
    "        # Query the network\n",
    "        outputs = nn.query(waveform.tolist())\n",
    "\n",
    "        # Identify predicted label\n",
    "        prediction = np.argmax(outputs)\n",
    "\n",
    "        # Correct label predicted to account for non-zero counting of neuron types and append to list of classified action potentials\n",
    "        predictions.append(prediction+1)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nn_spikes import NeuralNetwork, batchTrain, test\n",
    "import spike_tools, utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasources/spikes/training_data.csv')\n",
    "spikeLocations = pd.read_csv('./datasources/spikes/training_spike_locations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use labelled spikes to train the network, by first retrieving putative spike waveforms and passing it as input to NN. First we will split training data into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spike_tools.joinSpikes(data, spikeLocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect spikes yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['signalFiltered'] = spike_tools.bandPassFilter(data['signal'], lowCut=300, highCut=3000,order=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, predictedPeakIndexes = spike_tools.detectPeaks(data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get spike waveforms for predicted spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spike_tools.getSpikeWaveforms(predictedPeakIndexes, data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get spike waveforms for known spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownSpikeIndexes = data[data['knownSpike']==True].index\n",
    "data = spike_tools.getSpikeWaveforms(knownSpikeIndexes, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot spikes overlapped on original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.iloc[1152030-2500:1152030+2500, :]\n",
    "spike_tools.plotSpikes([sample['signal'], sample['signalFiltered']], [sample['knownSpike'], sample['predictedSpike']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waves = sample[sample['predictedSpike']==True]['waveform'].tolist()\n",
    "\n",
    "# px.line(x=np.linspace(0,100, 101), y=waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create datasets ready to pass to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training, data_validation, spikeIndexes_training, spikeIndexes_validation = spike_tools.splitData(data, predictedPeakIndexes, trainingShare=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utilities.createResultsRepo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastTrainingSpike = len(data_training[data_training['predictedSpike']==True])\n",
    "\n",
    "for hid in results.keys():\n",
    "    \n",
    "    nn = NeuralNetwork(input_nodes=101, \n",
    "                       hidden_nodes=int(hid), \n",
    "                       output_nodes=4, \n",
    "                       lr=0.1,\n",
    "                       error_function='difference-squared')\n",
    "\n",
    "    nn, trainingCurve, validationCurve, df1, df2 = batchTrain(data_training=data_training,\n",
    "                                                              data_validation=data_validation,\n",
    "                                                              spikeIndexes_training=spikeIndexes_training, \n",
    "                                                              spikeIndexes_validation=spikeIndexes_validation, \n",
    "                                                              nn=nn,\n",
    "                                                              epochs=30,\n",
    "                                                              plotCurves=False)\n",
    "    results[hid]['nn'] = nn\n",
    "    results[hid]['trainingCurve'] = trainingCurve\n",
    "    results[hid]['validationCurve'] = validationCurve\n",
    "    results[hid]['trainingData'] = df1\n",
    "    results[hid]['validationData'] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crappies = {}\n",
    "for crappy in [54412, 87433, 165493, 232479, 299250, 312319, 339791, 472193, 980407]:\n",
    "    crappies[str(crappy)] = data.loc[crappy-10: crappy+35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = data[data['predictedSpike']==True]['waveform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = results['500']['nn']\n",
    "assert isinstance(nn, NeuralNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['predictedSpike']==True, 'predictedClass'] = classifySpikes(waveforms, nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = pd.Series(data[data['predictedSpike']==True].index)\n",
    "truesShiftL = trues + 2\n",
    "truesShiftR = trues - 2\n",
    "mask = sorted(trues.append([truesShiftL, truesShiftR]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plotLearningCurves(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
