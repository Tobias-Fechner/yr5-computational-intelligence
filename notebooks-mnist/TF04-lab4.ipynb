{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open file, read data, close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the 100 training samples in read mode and read lines from file into memory\n",
    "file = open(\"datasources\\mnist_train_100.csv\", \"r\")\n",
    "data = file.readlines()\n",
    "\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One line == one sample. First item is label. Items are comma separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first line splitting based on commas\n",
    "values = data[0].split(\",\")\n",
    "\n",
    "# Take the list of pixels (exclude label at values[0]), and reshape to a 2D float array of pixels\n",
    "image = np.asfarray(values[1:]).reshape((28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 2D array as image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot this 2D array as an image, use the grey colour map and don’t interpolate\n",
    "plt.imshow(image, cmap='Greys', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3.nn_general import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open file, read data, close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST 100 training samples CSV file into a list\n",
    "file = open(\"datasources\\mnist_train_100.csv\", 'r')\n",
    "data = file.readlines()\n",
    "file.close()\n",
    "print(\"Length of trainin dataset: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a NN, with 28*28 input nodes, 100 hidden nodes, 10 output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(784, 100, 10, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the nn for each training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network on each trainingsample\n",
    "for record in data:\n",
    "    \n",
    "    # Split the record by the commas\n",
    "    pixelValues = record.split(',')\n",
    "    label = pixelValues.pop(0)\n",
    "    \n",
    "    # Scale and shift the inputs from 0..255 to 0.01..1\n",
    "    inputs = (np.asfarray(pixelValues) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    # Create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = np.zeros(nn.output_nodes) + 0.01\n",
    "    \n",
    "    # pixelValues[0] is the target label for this record\n",
    "    targets[int(label)] = 0.99\n",
    "    \n",
    "    # Train the network\n",
    "    nn.train(inputs.tolist(), targets.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST test samples CSV file into a list\n",
    "file = open(\"datasources\\mnist_test_10.csv\", 'r')\n",
    "data = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each record in training data, query nn and compare label prediction against correct result/ label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in data:\n",
    "    # Split the record by commas\n",
    "    pixelValues = record.split(',')\n",
    "    \n",
    "    # Correct label is the first value\n",
    "    correct_label = int(pixelValues.pop(0))\n",
    "    print(\"Correct label: \", correct_label)\n",
    "    \n",
    "    # Scale and shift the inputs\n",
    "    inputs = (np.asfarray(pixelValues)/255.0*0.99) + 0.01\n",
    "    \n",
    "    # Query the network\n",
    "    outputs = nn.queryNN(inputs.tolist())\n",
    "    \n",
    "    # Identify predicted label\n",
    "    prediction = np.argmax(outputs)\n",
    "    print(\"Prediction: \", prediction, '\\n')\n",
    "    \n",
    "    # Add to scorecard\n",
    "    if prediction == correct_label:\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "        # Take the list of pixels, and reshape to a 2D float array of pixels\n",
    "        image = np.asfarray(pixelValues).reshape((28, 28))\n",
    "        \n",
    "        # Plot this 2D array as an image, use the grey colour map and don’t interpolate\n",
    "        plt.imshow(image, cmap='Greys', interpolation='None')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard = np.asarray(scorecard)\n",
    "print(\"Success rate: \", (scorecard.sum()/scorecard.size)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3.nn_general import NeuralNetwork\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, nn):\n",
    "    # Train the neural network on each trainingsample\n",
    "    for record in data:\n",
    "\n",
    "        # Split the record by the commas\n",
    "        pixelValues = record.split(',')\n",
    "        label = pixelValues.pop(0)\n",
    "\n",
    "        # Scale and shift the inputs from 0..255 to 0.01..1\n",
    "        inputs = (np.asfarray(pixelValues) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # Create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(nn.output_nodes) + 0.01\n",
    "\n",
    "        # pixelValues[0] is the target label for this record\n",
    "        targets[int(label)] = 0.99\n",
    "\n",
    "        # Train the network\n",
    "        nn.train(inputs.tolist(), targets.tolist())\n",
    "        \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, nn):\n",
    "    \n",
    "    scorecard = []\n",
    "    successRate = 0\n",
    "    \n",
    "    for record in data:\n",
    "        # Split the record by commas\n",
    "        pixelValues = record.split(',')\n",
    "\n",
    "        # Correct label is the first value\n",
    "        correct_label = int(pixelValues.pop(0))\n",
    "\n",
    "        # Scale and shift the inputs\n",
    "        inputs = (np.asfarray(pixelValues)/255.0*0.99) + 0.01\n",
    "\n",
    "        # Query the network\n",
    "        outputs = nn.queryNN(inputs.tolist())\n",
    "\n",
    "        # Identify predicted label\n",
    "        prediction = np.argmax(outputs)\n",
    "\n",
    "        # Add to scorecard\n",
    "        if prediction == correct_label:\n",
    "            scorecard.append(1)\n",
    "        else:\n",
    "            scorecard.append(0)\n",
    "            \n",
    "    scorecard = np.asarray(scorecard)\n",
    "    successRate = (scorecard.sum()/scorecard.size)*100\n",
    "    return nn, successRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_train_100.csv\", 'r')\n",
    "data_training = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_test_10.csv\", 'r')\n",
    "data_testing = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify nn parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hidden_nodes = [50, 75, 100, 200, 300, 500, 700, 900, 1100]\n",
    "lrs = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dict to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_nodes in x_hidden_nodes:\n",
    "    for lr in lrs:\n",
    "        nn = NeuralNetwork(input_nodes=784, \n",
    "                           hidden_nodes=hidden_nodes, \n",
    "                           output_nodes=10, \n",
    "                           lr=lr)\n",
    "        for i in range(10):\n",
    "            nn = train(data_training, nn)\n",
    "        nn, successRate = test(data_testing, nn)\n",
    "        \n",
    "        results[str(hidden_nodes)+';'+str(lr)] = successRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestResult = max(results, key=lambda y: abs(results[y]))\n",
    "print(\"Best result of {}% achieved with...\\nnumber of hidden nodes: {}\\nlearning rate: {}\".format(\n",
    "    results[bestResult], \n",
    "    bestResult.split(';')[0], \n",
    "    bestResult.split(';')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with len(500) training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3.nn_general import NeuralNetwork\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_train_500.csv\", 'r')\n",
    "data_training = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_test_100.csv\", 'r')\n",
    "data_testing = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify nn parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hidden_nodes = [50, 75, 100, 200, 300, 500, 700, 900, 1100]\n",
    "lrs = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dict to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_nodes in tqdm(x_hidden_nodes):\n",
    "    for lr in lrs:\n",
    "        nn = NeuralNetwork(input_nodes=784, \n",
    "                           hidden_nodes=hidden_nodes, \n",
    "                           output_nodes=10, \n",
    "                           lr=lr)\n",
    "        for i in range(10):\n",
    "            nn = train(data_training, nn)\n",
    "        nn, successRate = test(data_testing, nn)\n",
    "        \n",
    "        results[str(hidden_nodes)+';'+str(lr)] = successRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestResult = max(results, key=lambda y: abs(results[y]))\n",
    "print(\"Best result of {}% achieved with...\\nnumber of hidden nodes: {}\\nlearning rate: {}\".format(\n",
    "    results[bestResult],\n",
    "    bestResult.split(';')[0], \n",
    "    bestResult.split(';')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "\n",
    "for hid in newDict.keys():\n",
    "    xValues = newDict[hid].keys()\n",
    "    yValues = newDict[hid].values()\n",
    "    plt.scatter(xValues, yValues)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (DON'T!) Use with full datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tqdm to have progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from lab3.nn_general import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hidden_nodes = [50, 75, 100, 200, 300, 500, 700, 900, 1100]\n",
    "lrs = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_train.csv\", 'r')\n",
    "data_training_full = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get full test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasources\\mnist_test.csv\", 'r')\n",
    "data_testing_full = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFull = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't run the below as it takes too long..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_nodes in tqdm(x_hidden_nodes):\n",
    "    for lr in lrs:\n",
    "        nnFull = NeuralNetwork(input_nodes=784, \n",
    "                               hidden_nodes=hidden_nodes, \n",
    "                               output_nodes=10, \n",
    "                               lr=lr)\n",
    "        nnFull = train(data_training_full, nnFull)\n",
    "        nnFull, successRate = test(data_testing_full, nnFull)\n",
    "        \n",
    "        resultsFull[str(hidden_nodes)+';'+str(lr)] = successRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestResultFull = max(resultsFull, key=lambda y: abs(resultsFull[y]))\n",
    "print(\"Best result of {}% achieved for full datasets with...\\nnumber of hidden nodes: {}\\nlearning rate: {}\".format(\n",
    "    resultsFull[bestResultFull], \n",
    "    bestResultFull.split(';')[0], \n",
    "    bestResultFull.split(';')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
